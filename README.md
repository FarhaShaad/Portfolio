# Portfolio
Hi! This is Farha. Welcome to my Data Science portfolio! This space showcases a curated collection of real-world and project-based work that reflects my ability to turn data into actionable insights. My projects span various domains‚Äîfrom finance and cryptocurrency to fake news detection‚Äîdemonstrating skills across the entire data pipeline.

üîç What You‚Äôll Find:
End-to-End Projects: Complete workflows including data collection, cleaning, analysis, visualization, and modeling.

Real-World Datasets: Applied to publicly available or scraped data that mimics practical business challenges.

Machine Learning Models: Built for classification, regression, and NLP, evaluated using appropriate metrics.

Interactive Visualizations: Used for storytelling and communicating insights to technical and non-technical stakeholders.

Code and Documentation: Clean, well-commented code with Jupyter notebooks, GitHub repositories, and final presentations.

üõ†Ô∏è Skills Demonstrated
Languages & Libraries: Python, Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, NLTK

Data Handling: Cleaning messy data, handling missing values, feature engineering, and EDA

Machine Learning: Logistic Regression, Decision Trees, Word2Vec, and more

Visualization & Reporting: Dashboard-ready plots and business-oriented summaries

üìå Featured Projects:
Trader Performance Analysis: Studied how emotions like fear and greed influence trading behavior.

Fake News Detection: Developed an NLP model using Word2Vec and Logistic Regression to detect misinformation.

Airbnb Pricing Analysis: Explored key factors that impact listing prices using regression models.

Banking Churn Prediction: Predicted customer churn with classification models and model interpretation techniques.

üë©‚Äçüíª Let‚Äôs Connect!
If you're interested in collaborating or hiring for data-driven roles, feel free to reach out!





## Trader Performance Analysis
This project explores the relationship between market sentiment and cryptocurrency trading performance. By integrating Fear & Greed Index data with real trading records, it uncovers behavioral patterns in decision-making, profitability, and trade direction under different sentiment conditions such as Fear, Greed, Extreme Greed, and Neutral.

üìå Key Highlights:

Data Integration: Merged public sentiment data (Fear & Greed Index) with real-world trade logs based on timestamps.

Data Cleaning & Processing: Handled inconsistent formats, parsed dates, managed missing classifications, and standardized features for analysis.

üîç Exploratory Data Analysis (EDA):

Distribution of trades under each sentiment.

Win rate and average PnL per sentiment.

BUY vs SELL behavior across market conditions.

üìä Visualizations:

* PnL distribution under fear vs greed (bar chart)

* PnL distribution by sentiment (Box Plot)

* PnL over time by sentiment (Line chart)

* Number of trades per sentiment (Bar chart)

* Buy vs Sell comparison (Pie chart)  

‚úÖ Insights Derived:

Lower win rates and higher volatility during periods of Fear.

Greed-driven trades showed higher average profitability but also risk.

BUY trades were more frequent during Greed, while SELL trades increased under Fear.

üõ†Ô∏è Tools & Technologies:

Python, Pandas, Matplotlib, Seaborn

Data wrangling, datetime handling, and group-based analysis






## Fake News Detection System
This project focuses on detecting misleading or false information in news articles using Natural Language Processing (NLP) and supervised learning techniques. With misinformation being a growing threat, especially across digital platforms, the goal was to build a robust classification model that can distinguish between real and fake news.

üîç Key Objectives
Classify news headlines/articles as real or fake

Apply text preprocessing techniques (tokenization, stopword removal, lemmatization)

Generate semantic meaning using Word2Vec embeddings

Train a Logistic Regression model for binary classification

Evaluate model performance using accuracy, confusion matrix, and ROC curve

üõ†Ô∏è Tech Stack
Language: Python

Libraries: Pandas, NumPy, Scikit-learn, NLTK, Gensim, Matplotlib, Seaborn

Modeling: Word2Vec + Logistic Regression

Data: Sourced from a labeled dataset of fake and real news headlines/articles

üìä Approach
Data Cleaning: Removed noise such as punctuation, special characters, and stopwords.

Tokenization & Lemmatization: Prepared the text for embedding.

Vectorization: Used Word2Vec to convert text into numerical vectors by averaging word embeddings.

Model Training: Trained a logistic regression model to classify the articles.

Evaluation: Achieved good accuracy with balanced results across both classes.

‚úÖ Outcome
Developed a scalable pipeline for text-based classification.

Gained deeper understanding of NLP preprocessing and word embeddings.

Demonstrated how classical ML methods can perform well when combined with strong feature engineering.

